---
title: Natural Language Processing (NLP)
layout: default
kb: true
top-category: Machine Learning
comments: true
wip: true
---

## Overview

## Large Language Models (LLM)

* [LLaMA: Open and Efficient Foundation Language Models - arXiv](https://arxiv.org/abs/2302.13971): Meta AI open-source LLM model.
  + [llama3 implemented from scratch](https://github.com/naklecha/llama3-from-scratch)
  + [llama.cpp](https://github.com/ggerganov/llama.cpp): fast, low overhead inference of LLaMA in C/C++.

## References

* [Attention Is All You Need- Arxiv](https://arxiv.org/pdf/1706.03762.pdf): introduces concepts of transformers and attention
* [Hugging Face](https://huggingface.co/): pre-trained NLP models & reference
* [Training data-efficient image transformers & distillation through attention- Facebook AI](https://arxiv.org/pdf/2012.12877.pdf)
* [The Illustrated Transform](http://jalammar.github.io/illustrated-transformer/): NLP walk-through

